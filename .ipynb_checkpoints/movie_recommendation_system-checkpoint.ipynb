{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommendation System\n",
    "\n",
    "\n",
    "![family_movie](images/family_movie.jpeg)\n",
    "\n",
    "\n",
    "You pick the movie, I'll choose the restaurant...\n",
    "\n",
    "## 1. Project Overview\n",
    "\n",
    "Choosing movies can be a stressful, high-stakes endeavor for anyone. And while users get stuck in indecision, the social media and streaming platfrom lose engagement and eventually profit. Fortunately, this program is here to help. It provides movie recommendations for any new user, based on their movie preferences. The program asks the user to rate five random movies from the [MovieLens](https://grouplens.org/datasets/movielens/) database of almost 10,000 movies. Based on the ratings, the program utilizes a user-based collaborative filtering model from [surprise](https://surpriselib.com/) to provide five recommendations.\n",
    "\n",
    "\n",
    "## 2. Business Case\n",
    "\n",
    "With the vast entertainment options available, low engagement and user churn in any social media or streaming service can hurt profit. Considering that 20% of adults are indecisive and 67% of relationship agreements never get resolved, picking a movie can be a daunting task, fueling decision paralysis and disengagement. Luckily, machine learning can relieve indecision by providing recommendations for any user, based on their preferences.\n",
    "\n",
    "## 3. Data Understanding\n",
    "\n",
    "### 3.1 Approach\n",
    "\n",
    "This recommendation system gets a user to rate five random movies from an existing database, and then returns five recommendations. The program uses a collaborative filtering model - no content-based or hybrid filtering was performed. Specifically, it relies on the model's ability to predict how any user would rate any movie. The `surprise` module is well suited for explicit ratings system with collaborative filter.\n",
    "\n",
    "Because no hybrid or content filtering is used, we're only interested in utilizing the data files containing our users, the movies, and the ratings. Other information won't be needed so we'll keep that in mind as we inspect the data.\n",
    "\n",
    "\n",
    "### 3.2 Source Data\n",
    "\n",
    "This project uses the Movielens dataset from the [GroupLens](https://grouplens.org/datasets/movielens/) lab at the University of Minnesota, which can be found in in the [`data`](#data) folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Background\n",
    "So, we have our data spanning over 4 separate csv files. We also have a README file which may tell us how this data interacts. Let's open that file to gain some insight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary\n",
      "=======\n",
      "\n",
      "This dataset (ml-latest-small) describes 5-star rating and free-text tagging activity from [MovieLens](http://movielens.org), a movie recommendation service. It contains 100836 ratings and 3683 tag applications across 9742 movies. These data were created by 610 users between March 29, 1996 and September 24, 2018. This dataset was generated on September 26, 2018.\n",
      "\n",
      "Users were selected at random for inclusion. All selected users had rated at least 20 movies. No demographic information is included. Each user is represented by an id, and no other information is provided.\n",
      "\n",
      "The data are contained in the files `links.csv`, `movies.csv`, `ratings.csv` and `tags.csv`. More details about the contents and use of all these files follows.\n",
      "\n",
      "This is a *development* dataset. As such, it may change over time and is not an appropriate dataset for shared research results. See available *benchmark* datasets if that is your intent.\n",
      "\n",
      "This and other GroupLens data sets are publicly available for download at <http://grouplens.org/datasets/>.\n",
      "\n",
      "\n",
      "Usage License\n",
      "=============\n",
      "\n",
      "Neither the University of Minnesota nor any of the researchers involved can guarantee the correctness of the data, its suitability for any particular purpose, or the validity of results based on the use of the data set. The data set may be used for any research purposes under the following conditions:\n",
      "\n",
      "* The user may not state or imply any endorsement from the University of Minnesota or the GroupLens Research Group.\n",
      "* The user must acknowledge the use of the data set in publications resulting from the use of the data set (see below for citation information).\n",
      "* The user may redistribute the data set, including transformations, so long as it is distributed under these same license conditions.\n",
      "* The user may not use this information for any commercial or revenue-bearing purposes without first obtaining permission from a faculty member of the GroupLens Research Project at the University of Minnesota.\n",
      "* The executable software scripts are provided \"as is\" without warranty of any kind, either expressed or implied, including, but not limited to, the implied warranties of merchantability and fitness for a particular purpose. The entire risk as to the quality and performance of them is with you. Should the program prove defective, you assume the cost of all necessary servicing, repair or correction.\n",
      "\n",
      "In no event shall the University of Minnesota, its affiliates or employees be liable to you for any damages arising out of the use or inability to use these programs (including but not limited to loss of data or data being rendered inaccurate).\n",
      "\n",
      "If you have any further questions or comments, please email <grouplens-info@umn.edu>\n",
      "\n",
      "\n",
      "Citation\n",
      "========\n",
      "\n",
      "To acknowledge use of the dataset in publications, please cite the following paper:\n",
      "\n",
      "> F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History and Context. ACM Transactions on Interactive Intelligent Systems (TiiS) 5, 4: 19:1â€“19:19. <https://doi.org/10.1145/2827872>\n",
      "\n",
      "\n",
      "Further Information About GroupLens\n",
      "===================================\n",
      "\n",
      "GroupLens is a research group in the Department of Computer Science and Engineering at the University of Minnesota. Since its inception in 1992, GroupLens's research projects have explored a variety of fields including:\n",
      "\n",
      "* recommender systems\n",
      "* online communities\n",
      "* mobile and ubiquitious technologies\n",
      "* digital libraries\n",
      "* local geographic information systems\n",
      "\n",
      "GroupLens Research operates a movie recommender based on collaborative filtering, MovieLens, which is the source of these data. We encourage you to visit <http://movielens.org> to try it out! If you have exciting ideas for experimental work to conduct on MovieLens, send us an email at <grouplens-info@cs.umn.edu> - we are always interested in working with external collaborators.\n",
      "\n",
      "\n",
      "Content and Use of Files\n",
      "========================\n",
      "\n",
      "Formatting and Encoding\n",
      "-----------------------\n",
      "\n",
      "The dataset files are written as [comma-separated values](http://en.wikipedia.org/wiki/Comma-separated_values) files with a single header row. Columns that contain commas (`,`) are escaped using double-quotes (`\"`). These files are encoded as UTF-8. If accented characters in movie titles or tag values (e.g. MisÃ©rables, Les (1995)) display incorrectly, make sure that any program reading the data, such as a text editor, terminal, or script, is configured for UTF-8.\n",
      "\n",
      "\n",
      "User Ids\n",
      "--------\n",
      "\n",
      "MovieLens users were selected at random for inclusion. Their ids have been anonymized. User ids are consistent between `ratings.csv` and `tags.csv` (i.e., the same id refers to the same user across the two files).\n",
      "\n",
      "\n",
      "Movie Ids\n",
      "---------\n",
      "\n",
      "Only movies with at least one rating or tag are included in the dataset. These movie ids are consistent with those used on the MovieLens web site (e.g., id `1` corresponds to the URL <https://movielens.org/movies/1>). Movie ids are consistent between `ratings.csv`, `tags.csv`, `movies.csv`, and `links.csv` (i.e., the same id refers to the same movie across these four data files).\n",
      "\n",
      "\n",
      "Ratings Data File Structure (ratings.csv)\n",
      "-----------------------------------------\n",
      "\n",
      "All ratings are contained in the file `ratings.csv`. Each line of this file after the header row represents one rating of one movie by one user, and has the following format:\n",
      "\n",
      "    userId,movieId,rating,timestamp\n",
      "\n",
      "The lines within this file are ordered first by userId, then, within user, by movieId.\n",
      "\n",
      "Ratings are made on a 5-star scale, with half-star increments (0.5 stars - 5.0 stars).\n",
      "\n",
      "Timestamps represent seconds since midnight Coordinated Universal Time (UTC) of January 1, 1970.\n",
      "\n",
      "\n",
      "Tags Data File Structure (tags.csv)\n",
      "-----------------------------------\n",
      "\n",
      "All tags are contained in the file `tags.csv`. Each line of this file after the header row represents one tag applied to one movie by one user, and has the following format:\n",
      "\n",
      "    userId,movieId,tag,timestamp\n",
      "\n",
      "The lines within this file are ordered first by userId, then, within user, by movieId.\n",
      "\n",
      "Tags are user-generated metadata about movies. Each tag is typically a single word or short phrase. The meaning, value, and purpose of a particular tag is determined by each user.\n",
      "\n",
      "Timestamps represent seconds since midnight Coordinated Universal Time (UTC) of January 1, 1970.\n",
      "\n",
      "\n",
      "Movies Data File Structure (movies.csv)\n",
      "---------------------------------------\n",
      "\n",
      "Movie information is contained in the file `movies.csv`. Each line of this file after the header row represents one movie, and has the following format:\n",
      "\n",
      "    movieId,title,genres\n",
      "\n",
      "Movie titles are entered manually or imported from <https://www.themoviedb.org/>, and include the year of release in parentheses. Errors and inconsistencies may exist in these titles.\n",
      "\n",
      "Genres are a pipe-separated list, and are selected from the following:\n",
      "\n",
      "* Action\n",
      "* Adventure\n",
      "* Animation\n",
      "* Children's\n",
      "* Comedy\n",
      "* Crime\n",
      "* Documentary\n",
      "* Drama\n",
      "* Fantasy\n",
      "* Film-Noir\n",
      "* Horror\n",
      "* Musical\n",
      "* Mystery\n",
      "* Romance\n",
      "* Sci-Fi\n",
      "* Thriller\n",
      "* War\n",
      "* Western\n",
      "* (no genres listed)\n",
      "\n",
      "\n",
      "Links Data File Structure (links.csv)\n",
      "---------------------------------------\n",
      "\n",
      "Identifiers that can be used to link to other sources of movie data are contained in the file `links.csv`. Each line of this file after the header row represents one movie, and has the following format:\n",
      "\n",
      "    movieId,imdbId,tmdbId\n",
      "\n",
      "movieId is an identifier for movies used by <https://movielens.org>. E.g., the movie Toy Story has the link <https://movielens.org/movies/1>.\n",
      "\n",
      "imdbId is an identifier for movies used by <http://www.imdb.com>. E.g., the movie Toy Story has the link <http://www.imdb.com/title/tt0114709/>.\n",
      "\n",
      "tmdbId is an identifier for movies used by <https://www.themoviedb.org>. E.g., the movie Toy Story has the link <https://www.themoviedb.org/movie/862>.\n",
      "\n",
      "Use of the resources listed above is subject to the terms of each provider.\n",
      "\n",
      "\n",
      "Cross-Validation\n",
      "----------------\n",
      "\n",
      "Prior versions of the MovieLens dataset included either pre-computed cross-folds or scripts to perform this computation. We no longer bundle either of these features with the dataset, since most modern toolkits provide this as a built-in feature. If you wish to learn about standard approaches to cross-fold computation in the context of recommender systems evaluation, see [LensKit](http://lenskit.org) for tools, documentation, and open-source code examples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = 'data/README.txt'\n",
    "\n",
    "with open(file_path) as file:\n",
    "    print(file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "This dataset (ml-latest-small) describes 5-star rating and free-text tagging activity from [MovieLens](http://movielens.org), a movie recommendation service. It contains 100836 ratings and 3683 tag applications across 9742 movies. These data were created by 610 users between March 29, 1996 and September 24, 2018. This dataset was generated on September 26, 2018.\n",
    "\n",
    "Users were selected at random for inclusion. All selected users had rated at least 20 movies. No demographic information is included. Each user is represented by an id, and no other information is provided.\n",
    "\n",
    "The data are contained in the files `links.csv`, `movies.csv`, `ratings.csv` and `tags.csv`. More details about the contents and use of all these files follows.\n",
    "\n",
    "### 3.3 Data Files\n",
    "\n",
    "#### Ratings Data File Structure (ratings.csv)\n",
    "\n",
    "All ratings are contained in the file `ratings.csv`. Each line of this file after the header row represents one rating of one movie by one user, and has the following format:\n",
    "\n",
    "    userId,movieId,rating,timestamp\n",
    "    \n",
    "#### Tags Data File Structure (tags.csv)\n",
    "\n",
    "All tags are contained in the file `tags.csv`. Each line of this file after the header row represents one tag applied to one movie by one user, and has the following format:\n",
    "\n",
    "    userId,movieId,tag,timestamp\n",
    "\n",
    "#### Movies Data File Structure (movies.csv)\n",
    "\n",
    "Movie information is contained in the file `movies.csv`. Each line of this file after the header row represents one movie, and has the following format:\n",
    "\n",
    "    movieId,title,genres\n",
    " \n",
    "#### Links Data File Structure (links.csv)\n",
    "\n",
    "Identifiers that can be used to link to other sources of movie data are contained in the file `links.csv`. Each line of this file after the header row represents one movie, and has the following format:\n",
    "\n",
    "    movieId,imdbId,tmdbId\n",
    "\n",
    "#### Summary of Files\n",
    "After reviewing the files, it appears that we only care about the `ratings.csv` file. It contains, per our description, \"one rating of one movie by one user.\" This is precisely the data we care about, so we can put aside the other files to pursue our collaborative filtering. So when we go into inspection and data preparation, we will keep this in mind\n",
    "\n",
    "### 3.4 Data Inspection\n",
    "Let's go ahead and see if we can verfiy some of this data in the `ratings.csv` file. I'm going to go ahead and import this file into PANDAS one-by-one to make sure the data matches the description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ratings File Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df = pd.read_csv('data/ratings.csv')\n",
    "ratings_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100836.000000</td>\n",
       "      <td>100836.000000</td>\n",
       "      <td>100836.000000</td>\n",
       "      <td>1.008360e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>326.127564</td>\n",
       "      <td>19435.295718</td>\n",
       "      <td>3.501557</td>\n",
       "      <td>1.205946e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>182.618491</td>\n",
       "      <td>35530.987199</td>\n",
       "      <td>1.042529</td>\n",
       "      <td>2.162610e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8.281246e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>177.000000</td>\n",
       "      <td>1199.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.019124e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>325.000000</td>\n",
       "      <td>2991.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.186087e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>477.000000</td>\n",
       "      <td>8122.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.435994e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>610.000000</td>\n",
       "      <td>193609.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.537799e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              userId        movieId         rating     timestamp\n",
       "count  100836.000000  100836.000000  100836.000000  1.008360e+05\n",
       "mean      326.127564   19435.295718       3.501557  1.205946e+09\n",
       "std       182.618491   35530.987199       1.042529  2.162610e+08\n",
       "min         1.000000       1.000000       0.500000  8.281246e+08\n",
       "25%       177.000000    1199.000000       3.000000  1.019124e+09\n",
       "50%       325.000000    2991.000000       3.500000  1.186087e+09\n",
       "75%       477.000000    8122.000000       4.000000  1.435994e+09\n",
       "max       610.000000  193609.000000       5.000000  1.537799e+09"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's interesting that the rating in 25-75 percentile range are from 3.0-4.0, meaning user generally rate movies favorably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userId       0\n",
       "movieId      0\n",
       "rating       0\n",
       "timestamp    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of movies:  9724 \n",
      "\n",
      "Number of ratings:  610\n"
     ]
    }
   ],
   "source": [
    "unique_movies = list(ratings_df['movieId'].unique())\n",
    "print('Number of movies: ', len(unique_movies), '\\n')\n",
    "\n",
    "unique_users = list(ratings_df['userId'].unique())\n",
    "print('Number of ratings: ', len(unique_users))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we have confirmed no null values, as well as 10,0836 movie ratings and a maximum userID of 610. All of our ratings our .5 - 5.0 and... we have 9,724 movies. This looks promising so far and matches our README.\n",
    "\n",
    "As we mentioned before, we're only concerne with the ratings file so we'll move on to data prep."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preparation\n",
    "\n",
    "### 4.1 Data Approach\n",
    "So we have a lot of data present in these files. For this project, we will only need to use the ratings file, and apply a matrix factorization to it.\n",
    "\n",
    "For the ratings file, we will drop the timestamp, as we're not as interested in the time series data. \n",
    "\n",
    "#### Dropping timestamp.\n",
    "I will drop the timestamp from each of the `ratings_df` and `tags_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings_df.drop('timestamp', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modeling & Evaluation\n",
    "As was noted in the previous section, we can create our model simply from the `ratings.csv` file. To create our baseline model, we're going to use the `surprise` module. We will compare SVD and a variety of KNN based methods within the `surprise` module to determine which is the most accurate for our dataset. For consistency sake, will use RSME (Root Square Mean Error).\n",
    "\n",
    "We will also establish a baseline of Random prediction ratings to see how the RSME compares.\n",
    "\n",
    "### 5.1 Random and Median for Baseline\n",
    "To see how well our model does, we will compare over a \"random\" model that predict a user's ratings. THis model will just pick ratings at random between (.5 and 5.0). We will also compare what the RMSE would be if we compared it to the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100831</th>\n",
       "      <td>610</td>\n",
       "      <td>166534</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100832</th>\n",
       "      <td>610</td>\n",
       "      <td>168248</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100833</th>\n",
       "      <td>610</td>\n",
       "      <td>168250</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100834</th>\n",
       "      <td>610</td>\n",
       "      <td>168252</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100835</th>\n",
       "      <td>610</td>\n",
       "      <td>170875</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100836 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  movieId  rating  predicted\n",
       "0            1        1     4.0        4.0\n",
       "1            1        3     4.0        2.0\n",
       "2            1        6     4.0        4.5\n",
       "3            1       47     5.0        2.5\n",
       "4            1       50     5.0        3.0\n",
       "...        ...      ...     ...        ...\n",
       "100831     610   166534     4.0        4.0\n",
       "100832     610   168248     5.0        0.5\n",
       "100833     610   168250     5.0        2.0\n",
       "100834     610   168252     5.0        4.5\n",
       "100835     610   170875     3.0        3.0\n",
       "\n",
       "[100836 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's create a column to test our first random column, which is a random number 0.5-5.0\n",
    "rand_rate = ratings\n",
    "rand_rate['predicted'] = np.random.randint(1,10, rand_rate.shape[0])/2\n",
    "\n",
    "rand_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We successfully created a new column called 'predicted' for all of the movies. Now, let's see if we can"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9375348294776356"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = np.sqrt(((rand_rate['predicted'] - rand_rate['rating']) ** 2).mean())\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our RMSE for this random baseline is 1.94. I hope we can beat that in our `surprise` modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's do the same test utilizing the median rating. According to our inspection above, the 50% score was 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100831</th>\n",
       "      <td>610</td>\n",
       "      <td>166534</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100832</th>\n",
       "      <td>610</td>\n",
       "      <td>168248</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100833</th>\n",
       "      <td>610</td>\n",
       "      <td>168250</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100834</th>\n",
       "      <td>610</td>\n",
       "      <td>168252</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100835</th>\n",
       "      <td>610</td>\n",
       "      <td>170875</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100836 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  movieId  rating  predicted\n",
       "0            1        1     4.0        3.5\n",
       "1            1        3     4.0        3.5\n",
       "2            1        6     4.0        3.5\n",
       "3            1       47     5.0        3.5\n",
       "4            1       50     5.0        3.5\n",
       "...        ...      ...     ...        ...\n",
       "100831     610   166534     4.0        3.5\n",
       "100832     610   168248     5.0        3.5\n",
       "100833     610   168250     5.0        3.5\n",
       "100834     610   168252     5.0        3.5\n",
       "100835     610   170875     3.0        3.5\n",
       "\n",
       "[100836 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "med_rate = ratings\n",
    "med_rate['predicted'] = 3.5\n",
    "\n",
    "med_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0425252322754481"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = np.sqrt(((med_rate['predicted'] - med_rate['rating']) ** 2).mean())\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aha! So by just predicting the median value, our RMSE is only 1.04. \n",
    "\n",
    "#### Summary\n",
    "Our random choice model was not very accurate, with an RMSE of 1.94. Our median value prediction model fared much better - and RMSE of 1.04. This is about a point off, which isn't bad for a model on a (0-5) scale.  We need a model to perform better than this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 `surpise` module models\n",
    "Now that we have established RSME from random and median models, let's go ahead and try some of the beefier models in surprise. First, we're going to read in our dataset and establish test and trainsets. Then we will proceed to work through our model types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading our Dataset\n",
    "To begin, we will go through the process of reading in our dataset into the surprise dataset format. This will make the subsequent modeling a little more fluid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the relevant item from surprise\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.prediction_algorithms import SVD\n",
    "from surprise.prediction_algorithms import KNNWithMeans, KNNBasic, KNNBaseline\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a way to validate the date, we're going to create a test and train set of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in dataset to surprise format\n",
    "from surprise import Reader, Dataset\n",
    "reader = Reader()\n",
    "data = Dataset.load_from_df(ratings,reader)\n",
    "\n",
    "# we will create a test set for validation, this will be used later when we fit the model\n",
    "trainset, testset = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users:  610 \n",
      "\n",
      "Number of ratings:  9724\n"
     ]
    }
   ],
   "source": [
    "#check to make sure item's loaded properly and create a new trainset.\n",
    "dataset = data.build_full_trainset()\n",
    "print('Number of users: ', dataset.n_users, '\\n')\n",
    "print('Number of ratings: ', dataset.n_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This matches our original check so... we've appeared to load the data successfully.\n",
    "#### Model-Based Methods (Matrix Factorization) - SVD with suprise module\n",
    "Below we will use the surprise method to create a SVD model, with tuned hyperparameters. We will utilize GridSearchCV for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   58.3s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  9.5min finished\n"
     ]
    }
   ],
   "source": [
    "## we will set up a SVD model with appropriate hyperparameters.\n",
    "\n",
    "#established some initial hyperparameters\n",
    "params = {'n_factors': [20, 50, 100],\n",
    "         'reg_all': [0.02, 0.05, 0.1],\n",
    "         'n_epochs': [5, 10, 15],\n",
    "         'lr_all': [.002, .005, .010]}\n",
    "\n",
    "#instantiate GridSearchCV model\n",
    "g_s_svd = GridSearchCV(SVD,param_grid=params,n_jobs = -1,joblib_verbose=5)\n",
    "\n",
    "#fit our ratings dataset \"data\" onto the model\n",
    "g_s_svd.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.8629065192573494, 'mae': 0.6627385253795459}\n",
      "{'rmse': {'n_factors': 100, 'reg_all': 0.05, 'n_epochs': 15, 'lr_all': 0.01}, 'mae': {'n_factors': 100, 'reg_all': 0.05, 'n_epochs': 15, 'lr_all': 0.01}}\n"
     ]
    }
   ],
   "source": [
    "print(g_s_svd.best_score)\n",
    "print(g_s_svd.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run the model we have an print the results of our testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8651\n",
      "0.8650715807530015\n"
     ]
    }
   ],
   "source": [
    "svd = SVD(n_factors=100, n_epochs=15, lr_all=0.010, reg_all=0.05)\n",
    "svd.fit(trainset)\n",
    "predictions = svd.test(testset)\n",
    "print(accuracy.rmse(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, we see a RMSE of .86. This... isn't bad on a scale of 0.5-5.0. Essentially it's under 1, which feels good and beats our baseline, but not under 0.5, which would feel better. Our model had an rmse of 0.87, let's establish that as OUR BASELINE MODEL.\n",
    "\n",
    "Our optimal parameters are n_factors = 100 and reg_all = .05. This is convenient that these are in the middle of our range. We'll do a few quick spot checks to see if we can improve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8640\n",
      "0.8639629266342134\n"
     ]
    }
   ],
   "source": [
    "svd = SVD(n_factors=100, n_epochs=20, lr_all=0.050, reg_all=0.05)\n",
    "svd.fit(trainset)\n",
    "predictions = svd.test(testset)\n",
    "print(accuracy.rmse(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8585\n",
      "0.8585001642972838\n"
     ]
    }
   ],
   "source": [
    "svd = SVD(n_factors=150, n_epochs=25, lr_all=0.010, reg_all=0.05)\n",
    "svd.fit(trainset)\n",
    "predictions = svd.test(testset)\n",
    "print(accuracy.rmse(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8597\n",
      "0.8596641766038512\n"
     ]
    }
   ],
   "source": [
    "svd = SVD(n_factors=200, n_epochs=30, lr_all=0.010, reg_all=0.05)\n",
    "svd.fit(trainset)\n",
    "predictions = svd.test(testset)\n",
    "print(accuracy.rmse(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So... it did go down, but it barely moved. Suffice to say that perhaps we've created a largely optimized model. We can return to this later. Our hyperparameters are {n_factors=150, n_epochs=25, lr_all=0.010, reg_all=0.05}\n",
    "\n",
    "#### Memory-Based Methods (Neighborhood-Based) KNN with surprise\n",
    "\n",
    "To begin with, we can calculate the more simple neighborhood-based approaches. We can start with KNNBasic. With KNNBasic, we'll need a trainset and a testset in order to cross-validate results. We also run a few examples to determine the best hyperparameters \n",
    "\n",
    "We'll import the relevant first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9753\n",
      "0.9753330994599322\n"
     ]
    }
   ],
   "source": [
    "#initiating KNN Basic with pearson similarity matric and user_based similiarity\n",
    "knn_basic = KNNBasic(sim_options={'name':'pearson', 'user_based':True})\n",
    "knn_basic.fit(trainset)\n",
    "predictions = knn_basic.test(testset)\n",
    "print(accuracy.rmse(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the KNN Basic, we have to set some of our hyper parameters. We'll try both \"cosine\" and \"pearson\". We'll also establish user based similarity, as there are fewer users than movies so this will save us considerable time. If we had thousands of users and only a handful of movies, we would consider an item  based similarity.\n",
    "\n",
    "Let's try cosine below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9752\n",
      "0.9751602971078402\n"
     ]
    }
   ],
   "source": [
    "#initiating KNN Basic with pearson correlation\n",
    "knn_basic = KNNBasic(sim_options={'name':'cosine', 'user_based':True})\n",
    "knn_basic.fit(trainset)\n",
    "predictions = knn_basic.test(testset)\n",
    "print(accuracy.rmse(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9706\n",
      "0.9706489484223293\n"
     ]
    }
   ],
   "source": [
    "#initiating KNN Basic with pearson correlation\n",
    "knn_basic = KNNBasic(sim_options={'name':'pearson', 'user_based':False})\n",
    "knn_basic.fit(trainset)\n",
    "predictions = knn_basic.test(testset)\n",
    "print(accuracy.rmse(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9787\n",
      "0.9787151489086232\n"
     ]
    }
   ],
   "source": [
    "#initiating KNN Basic with pearson correlation\n",
    "knn_basic = KNNBasic(sim_options={'name':'cosine', 'user_based':False})\n",
    "knn_basic.fit(trainset)\n",
    "predictions = knn_basic.test(testset)\n",
    "print(accuracy.rmse(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so we tried to utilize both hyperparameters here, and we got a larger error. Nearly an entire point. We'll sidestep the cross-validation here and see if we can run a different neighborhood based model. This model utilizes ALS (Alternative Linear Squares) method. We'll try both options and see which is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.8801\n",
      "0.8801035004209004\n"
     ]
    }
   ],
   "source": [
    "# cross validating with KNNBaseline\n",
    "knn_baseline = KNNBaseline(sim_options={'name':'pearson', 'user_based':True})\n",
    "knn_baseline.fit(trainset)\n",
    "predictions = knn_baseline.test(testset)\n",
    "print(accuracy.rmse(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.8814\n",
      "0.8813916557808571\n"
     ]
    }
   ],
   "source": [
    "# cross validating with KNNBaseline\n",
    "knn_baseline = KNNBaseline(sim_options={'name':'cosine', 'user_based':True})\n",
    "knn_baseline.fit(trainset)\n",
    "predictions = knn_baseline.test(testset)\n",
    "print(accuracy.rmse(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the KNN Baseline module performs better thand the KNN Basic, but not better than the SVD. \n",
    "\n",
    "#### Summary\n",
    "The method with the lowest RMSE (0.859) was a user-based, SVD with tuned hyperparameters {n_factors=150, n_epochs=25, lr_all=0.010, reg_all=0.05}.\n",
    "\n",
    "Let's go ahead and build our recommender using the SVD!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Implementation\n",
    "### 6.1 Overview\n",
    "Now that we have this model (Step 1), we will proceed to develop our recommender system, including how to work through the  \"cold start\" problem. We will do that utilizing the following steps.\n",
    "\n",
    "Step 1 (previously created): Prior to input from the new user, we created user-based collaborative filtering prediction model to predict how an existing user would rate a movie from the database. \n",
    "\n",
    "Step 2: Prompt user to rate five movies.\n",
    "\n",
    "Step 3: Add user's rating to the existing database\n",
    "\n",
    "Step 4: Use the model from step 1 to predict how new users movie would rate (1-5) for all movies in the database and sort highest to lowest \n",
    "\n",
    "Step 5: Output the top 5 recommendations \n",
    "\n",
    "So... let's go to Step 2.\n",
    "\n",
    "### 6.2 - Step 2: Prompt User\n",
    "Below is the function used to prompt a user to rate movies, (1 - 5) for random movies in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function to be called based on the number of movies created. This will include an option for genre\n",
    "def movie_rater(movie_df, num, last_user, genre=None):\n",
    "    userID = last_user + random.randint(0,1000)\n",
    "    rating_list = []\n",
    "    \n",
    "#loop through for each recommendation\n",
    "    while num > 0:\n",
    "        \n",
    "        if genre:\n",
    "            movie = movie_df[movie_df['genres'].str.contains(genre)].sample(1)\n",
    "        else:\n",
    "            movie = movie_df.sample(1)\n",
    "        \n",
    "        print(f\"\\n {movie.title} {movie.genres}\\n\")\n",
    "        rating = input('How do you rate this movie on a scale of 1-5, press n if you have not seen:\\n')\n",
    "    \n",
    "        if rating == 'n':\n",
    "            continue\n",
    "        elif (0 < float(rating) and float(rating) < 5.1):\n",
    "            rating_one_movie = {'userId':userID,'movieId':movie['movieId'].values[0],'rating':rating}\n",
    "            rating_list.append(rating_one_movie) \n",
    "            num -= 1\n",
    "        else:\n",
    "            rating_again = input(\"Please choose either n, if you haven't seen it, or a scale of 1-5 if you have:\\n\")\n",
    "            if rating_again == 'n':\n",
    "                continue\n",
    "            elif (0 < float(rating) and float(rating) < 5.1):\n",
    "                rating_one_movie = {'userId':userID,'movieId':movie['movieId'].values[0],'rating':rating_again}\n",
    "                rating_list.append(rating_one_movie) \n",
    "                num -= 1\n",
    "            else:\n",
    "                print(\"You're struggling with directions. Let's try a different movie...\\n\")\n",
    "                continue\n",
    "    return rating_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 6542    Sydney White (2007)\n",
      "Name: title, dtype: object 6542    Comedy\n",
      "Name: genres, dtype: object\n",
      "\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen:\n",
      "n\n",
      "\n",
      " 5153    Man Who Came to Dinner, The (1942)\n",
      "Name: title, dtype: object 5153    Comedy\n",
      "Name: genres, dtype: object\n",
      "\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen:\n",
      "n\n",
      "\n",
      " 8655    John Mulaney: New In Town (2012)\n",
      "Name: title, dtype: object 8655    Comedy\n",
      "Name: genres, dtype: object\n",
      "\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen:\n",
      "5\n",
      "\n",
      " 6895    Saw V (2008)\n",
      "Name: title, dtype: object 6895    Crime|Horror|Thriller\n",
      "Name: genres, dtype: object\n",
      "\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen:\n",
      "4\n",
      "\n",
      " 9491    CHiPS (2017)\n",
      "Name: title, dtype: object 9491    Action|Comedy|Drama\n",
      "Name: genres, dtype: object\n",
      "\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen:\n",
      "1\n",
      "\n",
      " 1984    Mummy, The (1959)\n",
      "Name: title, dtype: object 1984    Horror\n",
      "Name: genres, dtype: object\n",
      "\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen:\n",
      "1\n",
      "\n",
      " 1261    Starship Troopers (1997)\n",
      "Name: title, dtype: object 1261    Action|Sci-Fi\n",
      "Name: genres, dtype: object\n",
      "\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen:\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Let's call our new function\n",
    "last_user = ratings['userId'].max() \n",
    "user_rating = movie_rater(movies_df, 5, last_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so we prompted the user and got their viewing history. Let's move on to Step 3.\n",
    "\n",
    "### 6.3 - Step 3: Add user ratings to database and rerun model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add the new ratings to the original ratings DataFrame\n",
    "user_ratings = pd.DataFrame(user_rating)\n",
    "new_ratings_df = pd.concat([ratings, user_ratings], axis=0)\n",
    "new_data = Dataset.load_from_df(new_ratings_df,reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whelp... that was easy, we now have the user's information here in the database... Let's go to Step 4\n",
    "\n",
    "### 6.4 - Step 4: Predict new user movie preferences\n",
    "\n",
    "Now that we have a \"new\" database, similar to the old one, let's rerun our prediction model. First, we will rerun the model, and then we will create new predictions for all of the movie's in the database, sort from greatest to least."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x2cfb3bc0520>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a model using the new combined DataFrame, recall our parameters from before {(n_factors=150, n_epochs=25, lr_all=0.010, reg_all=0.05)}\n",
    "svd = SVD(n_factors=150, n_epochs=25, lr_all=0.010, reg_all=0.05)\n",
    "svd.fit(new_data.build_full_trainset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for the user, to do this, predict ratings for every movie out there and order it from lowest to highest\n",
    "list_of_movies = []\n",
    "\n",
    "for m_id in ratings['movieId'].unique():\n",
    "    list_of_movies.append((m_id,svd.predict(last_user,m_id)[3]))\n",
    "\n",
    "ranked_movies = sorted(list_of_movies, key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 - Step 5: Provide recommendations for 5 movies.\n",
    "\n",
    "Now that we have a \"new\" database, similar to the old one, let's rerun our prediction model. First, we will rerun the model, and then we will create new predictions for all of the movie's in the database, sort from greatest to least."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendation #  1 :  659    Godfather, The (1972)\n",
      "Name: title, dtype: object \n",
      "\n",
      "Recommendation #  2 :  224    Star Wars: Episode IV - A New Hope (1977)\n",
      "Name: title, dtype: object \n",
      "\n",
      "Recommendation #  3 :  898    Star Wars: Episode V - The Empire Strikes Back...\n",
      "Name: title, dtype: object \n",
      "\n",
      "Recommendation #  4 :  5621    Neon Genesis Evangelion: The End of Evangelion...\n",
      "Name: title, dtype: object \n",
      "\n",
      "Recommendation #  5 :  900    Raiders of the Lost Ark (Indiana Jones and the...\n",
      "Name: title, dtype: object \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# return the top n recommendations using the \n",
    "def recommended_movies(user_ratings,movie_title_df,n):\n",
    "        for idx, rec in enumerate(user_ratings):\n",
    "            title = movie_title_df.loc[movie_title_df['movieId'] == int(rec[0])]['title']\n",
    "            print('Recommendation # ', idx+1, ': ', title, '\\n')\n",
    "            n-= 1\n",
    "            if n == 0:\n",
    "                break\n",
    "            \n",
    "recommended_movies(ranked_movies,movies_df,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there we have it! I like all of these movies except for no. 4. I haven't seen it. Maybe I'll watch it later.\n",
    "\n",
    "### Summary\n",
    "So... we were able to successfully implement a collaborative filtering model utilizing the surprise module and the Movielens database. Our model has an RMSE of .854, which is less than our baseline random model and less than 1 point. And... we were able to successfully implement to build a recommender system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
